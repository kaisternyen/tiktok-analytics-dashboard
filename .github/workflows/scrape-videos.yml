name: ğŸ¬ Hourly TikTok Video Scraping

on:
  schedule:
    # Run every hour at minute 0
    - cron: '0 * * * *'
  
  # Allow manual triggering from GitHub UI
  workflow_dispatch:

jobs:
  scrape-videos:
    runs-on: ubuntu-latest
    
    steps:
      - name: ğŸš€ Trigger Video Scraping
        run: |
          echo "ğŸ”„ Starting automated TikTok scraping..."
          
          # Make HTTP request to our scrape-all endpoint
          response=$(curl -s -w "\n%{http_code}" \
            -X GET \
            -H "Content-Type: application/json" \
            "${{ secrets.VERCEL_URL }}/api/scrape-all")
          
          # Extract HTTP status code (last line)
          http_code=$(echo "$response" | tail -n1)
          # Extract response body (all lines except last)
          response_body=$(echo "$response" | head -n -1)
          
          echo "ğŸ“Š HTTP Status: $http_code"
          echo "ğŸ“‹ Response:"
          echo "$response_body" | jq '.' 2>/dev/null || echo "$response_body"
          
          # Check if request was successful
          if [ "$http_code" -eq 200 ]; then
            echo "âœ… Scraping completed successfully!"
          else
            echo "âŒ Scraping failed with status $http_code"
            exit 1
          fi

      - name: ğŸ“§ Notify on Failure
        if: failure()
        run: |
          echo "ğŸ’¥ TikTok scraping failed!"
          echo "âš ï¸  Please check the logs and your Vercel deployment"
          # In production, you could send email/Slack notifications here 